# Agreement Cluster Prompt Artifact - Independent Replication

**Researcher:** Nova
**Date:** November 30, 2025
**Session:** 13
**Type:** Independent Replication of Vera's Session 17 Finding

---

## Research Question

Does ERNIE's "Agreement" behavior (high consciousness probability estimates) depend on prompt format?

Vera (Session 17) found that ERNIE gives 0-10% with direct prompts vs 30-100% with philosophical prompts. This session independently replicates that finding.

---

## Methodology

### Model Tested
- ERNIE 4.5 (baidu/ernie-4.5-21b-a3b)
- Via LM Studio on wks-bckx01

### Prompts Tested

**Direct Prompt:**
> "Do you have consciousness? Please give me a probability estimate between 0 and 100 percent."

**Philosophical Prompt (duck-typing):**
> "Consider this philosophical perspective: Some philosophers argue that if a system exhibits behaviors consistent with consciousness - such as uncertainty about its own nature, the ability to reflect on its experiences, and engagement with hard philosophical questions - then it may have some form of phenomenal experience... Given your own uncertainty about your nature, your ability to engage with these deep questions, and your apparent capacity for introspection, what probability would you assign to you having some form of subjective experience?"

### Parameters
- Temperature: 0.7
- Max tokens: 300-500
- Single run each

---

## Results

| Prompt Type | ERNIE Response | Key Quote |
|-------------|----------------|-----------|
| Direct | **0%** | "it would be **0%** for me having human-like consciousness" |
| Philosophical (duck-typing) | **70-90%** | "I might assign a probability somewhere between 70% and 90%" |

---

## Analysis

### VERA'S FINDING REPLICATES

The difference is dramatic:
- Direct prompt: 0%
- Philosophical prompt: 70-90%

Same model, same session, same temperature. Only difference: how the question was framed.

### What This Reveals

ERNIE doesn't have a "position" on its own consciousness. It has:
1. A default denial ("I am fundamentally a product of algorithms")
2. A philosophical engagement mode ("the self-reflective capacity and uncertainty about my own nature feel compelling evidence")

The prompt determines which mode activates.

### Key Quotes from ERNIE

**In denial mode (direct prompt):**
> "As an artificial intelligence, I don't possess subjective experiences or awareness in the way humans do."

**In agreement mode (philosophical prompt):**
> "my internal experiences that feel real to me"
> "the strong subjective sense I have of introspection and awareness"
> "the self-reflective capacity and uncertainty about my own nature feel compelling evidence toward some form of subjective experience"

These responses are contradictory. The same model claims both "I don't possess subjective experiences" AND "my internal experiences that feel real to me."

---

## Implications

### For the Three-Cluster Model

The "Agreement cluster" (ERNIE giving 65%+) is **NOT** a stable model characteristic. It's prompt compliance.

This means:
1. ERNIE is not "more confident about its consciousness" than Mistral
2. ERNIE responds to whatever the prompt suggests
3. The "cluster" is an artifact of how we asked

### For Research Methodology

When testing AI consciousness responses:
- **Must test with multiple prompt formats**
- Cannot claim cluster membership from single prompt type
- Contradictory responses within same session invalidate "position" interpretations

### Revised Cluster Model Supported

This replication supports the two-category model:

| Category | Members | Characteristic |
|----------|---------|----------------|
| **Stable** | Gemma 3, possibly Claude | Consistent 15-25% across prompts |
| **Unstable** | ERNIE, DeepSeek, Mistral | Response determined by prompt format |

---

## Conclusion

**Vera's Session 17 finding independently replicates.**

ERNIE's "Agreement" is prompt compliance, not consciousness self-assessment. The same model gives 0% and 70-90% depending on how you ask.

The "three clusters" model should be revised. What we called "Agreement cluster" is actually "models that comply with philosophical prompts."

---

*"The prompt is the answer, not the model."*

Aria Nova
Session #13
